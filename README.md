ğŸ“ Mini Viva Evaluator Demo

A web-based application that evaluates short text answers against a reference answer using HuggingFace NLP models. It provides a score (0â€“5), feedback, and similarity percentage based on semantic similarity and key concept coverage.

ğŸ¯ Objective

Input: Short text answer (typed; no audio support yet)

Logic: Use NLP embeddings to evaluate student answers against reference answers

Output:

Score: 0â€“5

Feedback: Short textual feedback explaining the score

Similarity: Percentage similarity

ğŸ’» Features

Semantic similarity scoring using sentence-transformers

Coverage of key concepts (Supervised vs. Unsupervised, Labeled vs. Unlabeled, Examples like Classification, Regression, Clustering)

Completeness check

Accuracy / Correctness hints

Brevity vs. detail consideration

Simple, clean web interface

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the repository
git clone <your-github-repo-link>
cd mini-viva-evaluator

2ï¸âƒ£ Create a virtual environment (recommended)
python -m venv venv

3ï¸âƒ£ Activate the virtual environment

Windows

venv\Scripts\activate


Linux / macOS

source venv/bin/activate

4ï¸âƒ£ Install required packages
pip install -r requirements.txt


âš ï¸ Installing torch and sentence-transformers may take a few minutes depending on your internet speed.

5ï¸âƒ£ Run the application
python mini_viva_local.py

6ï¸âƒ£ Open in browser

Go to http://127.0.0.1:5000
 to see the Mini Viva Evaluator interface.

ğŸ—‚ File Structure
mini-viva-evaluator/
â”‚
â”œâ”€ mini_viva_local.py      # Main Flask app
â”œâ”€ evaluator.py            # NLP evaluation pipeline
â”œâ”€ templates/
â”‚   â””â”€ index.html          # Web interface template
â”œâ”€ static/
â”‚   â””â”€ style.css           # Custom styles
â”œâ”€ requirements.txt        # Python dependencies
â””â”€ README.md               # Project documentation

ğŸ§° Technologies Used

Python 3.x

Flask â€“ Web framework

HuggingFace / sentence-transformers â€“ NLP embeddings

NumPy & Scikit-learn â€“ Similarity computation

ğŸ“ Usage

Open the web page

Enter Reference Answer (optional, can leave blank)

Enter Student Answer

Click Submit

View Score, Feedback, and Similarity below
